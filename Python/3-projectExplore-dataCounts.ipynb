{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c621e7650d4943",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Visualizing your NLP data: An Orientation with a Sorted Bar Plot\n",
    "\n",
    "* This homework is building on cells from the previous assignment, and then moving on to show you how to visualize the data.\n",
    "* We'll start with the usual **pip installs** you need:\n",
    "    * **pip install numpy**\n",
    "    * **pip install seaborn**\n",
    "    * **pip install matplotlib**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install saxonche\n",
    "# !pip install pathlib\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import re as regex\n",
    "# re lets us work with regular expressions in Python\n",
    "from saxonche import PySaxonProcessor\n",
    "from os import getcwd\n",
    "# this lets us retrieve the current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204f234-ebbb-4867-9cb2-d3494379b392",
   "metadata": {},
   "source": [
    "Remember the spaCy language models? Let's try loading loading the large one to get the maximum amount of information from it! \n",
    "There's a lot we can experiment with from spaCy, so here's a link to the documentation for our ready reference:\n",
    "<https://spacy.io/usage/spacy-101> \n",
    "\n",
    "We're going to start by just reviewing its POS (part of speech) and NER (named entity recognition) taggers to see what we can see in your project files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c9b20-f094-4cc2-9c51-c9ce642a81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.cli.download(\"en_core_web_lg\")\n",
    "# ONLY NEED ABOVE LINE ONCE. REMEMBER: COMMENT OUT THE ABOVE LINE THE NEXT TIME YOU RUN THIS.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3aa2a5-fef7-40d0-921a-668b9021f09c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Okay, let's explore some project files!\n",
    "We've loaded the XML directory prepared by the Futurama team for our example here. \n",
    "\n",
    "* If you have some basic XML right now, like the Futurama team has prepared, we can easily scope in tagged sections of your collection. Swap out the Futurama collection with yours, and adjust the Python code below accordingly.\n",
    "* If you don't have XML at this point, you can work around this over text files, or just explore the Futurama collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ed67e-3a24-49d0-8a92-526e941ccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE SOME FILE PATHS FOR INPUT, AND (ONCE WE'RE READY) OUTPUT\n",
    "InputPath = 'futurama-xml'\n",
    "OutputPath = 'testOutput' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842d99e-4b58-4681-aa39-2ff13aaabde0",
   "metadata": {},
   "source": [
    "# You can SKIP the next (XPath) code block for now \n",
    "(We're leaving it for review: we'll find a good use for it later).\n",
    "\n",
    "The next cell demonstrates the xpath() function, set up to run over individual files.\n",
    "Let's look at how it returns information about distinct values of speakers. We're exploring distinct-values() and count() functions here. Try removing them and putting them back to see what the effect of distinct-values() is on the count. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84065536-1328-4c31-887b-57ea4576301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextFiles(InputPath):\n",
    "    # This function uses XPath to read the XML input\n",
    "    for file in os.listdir(InputPath):\n",
    "        if file.endswith('.xml'):\n",
    "            filepath = f\"{InputPath}/{file}\"\n",
    "            with PySaxonProcessor(license=False) as proc:\n",
    "                xml = open(filepath, encoding='utf-8').read()\n",
    "                # ebb: Here we apply the Saxon processor to read files with XPath.\n",
    "                xp = proc.new_xpath_processor()\n",
    "                node = proc.parse_xml(xml_text=xml)\n",
    "                xp.set_context(xdm_item=node)\n",
    "\n",
    "                # From here on, we select the string that Python will send to NLP. \n",
    "                # xpath = xp.evaluate('//your/xpath/here')\n",
    "                xpath = xp.evaluate('//speak/@who => distinct-values() => sort()')\n",
    "                count = xp.evaluate('//speak/@who => distinct-values() => count()')\n",
    "                string = str(xpath)\n",
    "                print(xpath)\n",
    "                # xpath is going to go file by file.\n",
    "             \n",
    "readTextFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4454e36-c2af-4d35-ad60-964a78567779",
   "metadata": {},
   "source": [
    "## XQuery Blocks\n",
    "Review: XQuery is what we want to use to help read data from across a whole directory, or \"corpus\" collection of files. \n",
    "XQuery can be written as a separate file (with .xql or .xquery extension) in oXygen over a directory. But we will find it more useful \n",
    "to apply it in Python if we're working on natural language processing applications. \n",
    "\n",
    "### Setting up XQuery in Python \n",
    "We use the same \"boilerplate\" PySaxonProcessor lines, but switch from xpath to the xquery processor.\n",
    "\n",
    "\n",
    "Requirements: \n",
    "* We need all the xq lines to plug this processing into Python. You can use this code as a starter for your projects.\n",
    "* The XQuery script is written inside a quoted block in the set_query_content() function that needs to take a quoted string, just like in the cell below.\n",
    "* We need the run_query_to_value() function to execuit the script we're writing.\n",
    "  \n",
    "\n",
    "**Reading the collection**: We're setting this up to read a `collection()` function, which is a directory of XML files. \n",
    "**Writing XQuery**: This involves setting simple variables equal to xpath expressions. XQuery variables are defined with a `$`.\n",
    "**XQuery Comments**: look like sideways smiley faces. `(: I'm an XQuery comment :)`\n",
    "\n",
    "Let's take a look:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f62be-51be-472c-9ce1-6fbe9143d141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        # This only works on Mac / Linux: xq.set_query_base_uri('file://'+getcwd()+'/')\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "let $count := count($speakers)\n",
    "return $speakers\n",
    "\n",
    "   (: ebb: I'm writing in an XQuery comment, and pointing out you can define and return any variable you want in the XQuery zone. :)\n",
    "   (: ebb: Try changing this one to return $speakers instead of the $count variable. :)\n",
    "   (: ebb: We're writing an query-based syntax called FLWOR (pronounced \"flower\") and every FLWOR requires a return statement at the end. :)\n",
    "    \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                               \n",
    "xqueryOverFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9a52a-1c66-4f2d-abb4-81408479de29",
   "metadata": {},
   "source": [
    "## What's the difference? \n",
    "\n",
    "Notice that you return just one count for the entire collection, not 72 different counts for the speakers in each file.\n",
    "How can we use this? \n",
    "\n",
    "We can get pull information from across the entire collection and find out literally who has the most speeches in the whole series. \n",
    "Take a look at this code. Don't worry if you don't know how to write it yet. I just want to show you for demonstration purposes! \n",
    "What's here is a nearly full \"FLWOR statement\" which stands for :\n",
    "\n",
    "* For\n",
    "* Let\n",
    "* Where\n",
    "* Order by\n",
    "* Return\n",
    "\n",
    "The only things required in a FLWOR statements are L and R. The others give you extra powers like we're seeing here.\n",
    "\n",
    "**IMPORTANT: You're only allowed one return per FLWOR.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c8f11-81c1-4e3a-a182-9437e50870b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "let $count := count($speakers)\n",
    "for $sp in $speakers\n",
    "    let $count := $futurama//speak[@who = $sp] => count()\n",
    "    where $count > 100\n",
    "    order by $count descending\n",
    "    return ($sp || ':  ' || $count)\n",
    " \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                            \n",
    "\n",
    "xqueryOverFiles(InputPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14970c9-f8e6-4cd5-86ed-32765e274c8c",
   "metadata": {},
   "source": [
    "For this notice how we can move **deliberately** in XQuery from information on the whole collection, to information based on individuals in a series.\n",
    "The counts we're seeing are NOT based on files, but on info about each speaker! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b430fc-4404-4a1c-879f-c6909dba3231",
   "metadata": {},
   "source": [
    "## For statements, measurements, order by, return\n",
    "\n",
    "\n",
    "* Let's choose a character from Futurama who gets a LOT of speeches and use XQuery to pull all their speeches from across the entire collection into one return.\n",
    "The next code block is written to show you how to get all the speeches of one character in the WHOLE collection. You can change this to any other character you wish.\n",
    "* Let's go through each speech individually and meaasure it: \n",
    "* Try out defining a new variable in the XQuery, to use the `string-length()` function, so you can measure the text of the speeches. Try it out!\n",
    "\n",
    "* We're going to write a for statement so we can evaluate each speech, and order our results based on how long the speeches are,\n",
    "     * We'll use the XPath `string-length()` function to measure each speech\n",
    "     * We'll work through an XQuery `for` and `order by`\n",
    "     * Let's see if we can return the speeches from shortest to longest, then try adding the word `descending` to order them longest to shortest!\n",
    "\n",
    "\n",
    "* YOUR TURN: Edit the code below to return some alternative information! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18659ee5-2877-412b-b627-059c5c5c6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xqueryAndNLP(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $benderSpeeches := $futurama//speak[@who=\"BENDER\"]\n",
    "let $benderTextsOnly := $benderSpeeches/text() \n",
    "for $bt in $benderTextsOnly\n",
    "   let $length := $bt ! string-length()\n",
    "   where $length gt 20\n",
    "   order by $length descending\n",
    "   return $bt\n",
    "''')\n",
    "        # We started with this: r = xq.run_query_to_value() \n",
    "        # If you use this you need to convert r to a string in Python. r = str(run_query_to_value())\n",
    "        # There's a run_query_to_string() option that's convenient so I'm using it here! \n",
    "        r = xq.run_query_to_string()\n",
    "        return r\n",
    "        # print(r)                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990125f6-ce31-4842-bf8e-6c951412def0",
   "metadata": {},
   "source": [
    "## Experimenting with some functions\n",
    "\n",
    "\n",
    "Remember how we were going to apply some NLP from spaCy? The next part of this exercise is to take the output of this XQuery function and pass it to the spaCY language model!\n",
    "\n",
    "We need XQuery in our function above to return just one string if we want to deliver that to spaCY and NLP tools. The way I left this code, it's returning thousands of strings.\n",
    "\n",
    "* So here's your challenge: Write some code that returns all the text of a different speaker. (Or adjust the code to use in your project.)\n",
    "* The `r` variable is storing the XQuery output. I have updated `r` to be xq.run_query_to_string() which should output a single string. If it syou can convert it to a single string in Python with `str()`.\n",
    "* Then make sure it's returning a single string when you print(r). You may need to convert `r` \n",
    "* **Write some new code** that delivers this single string to be processed with spaCy in some way.\n",
    "    * You can build your code in a new cell block below this one.\n",
    "    *  You'll probably want to review [this spaCy NLP assignment](https://github.com/newtfire/textAnalysis-Hub/blob/main/python-nlp-exercise1.md#write-some-python-code-to-do-the-following)\n",
    "    * Write your code to return any information of interest from spaCy, following the spaCy documentation as we did in that earlier assignment! Try looking for one or two different kinds of language. What are the most popular verbs, adjectives, nouns? Try out the NER (named entity recognition)...Write your code in your copy of this Jupyter Notebook to complete this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574b646-79c0-459b-8f84-17f053e81108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "inputstring = xqueryAndNLP(InputPath)\n",
    "# start playing with spaCy and nlp:\n",
    "benderWords = nlp(inputstring)\n",
    "# print(benderWords)\n",
    "\n",
    "\n",
    "BenderLemmas = []\n",
    "for token in benderWords:\n",
    "    if token.pos_ == \"VERB\":\n",
    "        lemma = token.lemma_\n",
    "        BenderLemmas.append(lemma)\n",
    "\n",
    "# Okay, we'll use python's Counter() find out how frequently each verb lemma shows up in the entire verb list.\n",
    "# Counter() removes duplicates and counts the number of times something appears. \n",
    "# And it outputs a dictionary of key:value pairs already sorted from highest to lowet count.\n",
    "\n",
    "lemmaFreq = Counter(BenderLemmas)\n",
    "\n",
    "print(f\"Lemma frequency {lemmaFreq}\")\n",
    "\n",
    "# We can even calculate the percentage each verb is used.\n",
    "# The totalVerbCount will be the length of the BenderLemmas list.\n",
    "\n",
    "totalVerbCount = len(BenderLemmas) \n",
    "# print(f\"total verb count: {totalVerbCount}\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6635ec-f023-4df9-9462-6ee4602c85fb",
   "metadata": {},
   "source": [
    "## Plotting some output in SVG\n",
    "Here's how to do this with the seaborn library. You can work with a range of palettes here optimized in different ways for displaying graph data.\n",
    "First some installs. matplotlib and seaborn libraries work together when we start plotting. These are some frequently used visualization libraries in Python, and you can customize them for display in jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc53804-9567-4d4c-80ca-f1cd81f911b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy \n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib\n",
    "\n",
    "# Counter is an amazing Python module: it's going to save us some lines of code.\n",
    "# We'll use it when we want to get count information of how often distinct forms of a word occur in our colleciton. \n",
    "# Fun things to do with Counter: https://realpython.com/python-counter/#plotting-categorical-data-with-matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb2780-18d3-456d-94f6-0b4d60fa4e67",
   "metadata": {},
   "source": [
    "### How much to plot? And how to display? \n",
    "If we're displaying in a Jupyter Notebook, there are some display configurations to set, marked with a `%` in the next cell. \n",
    "\n",
    "We don't want to plot every last word here. But we have a lot of data, so we can experiment\n",
    "To access data in our Counter list and keep it organized from highest to lowest value, we use `most_common()`.\n",
    "Then we can slice it to store however many we want to plot. [:10] would plot the first 11 values since python starts counting from zero.\n",
    "\n",
    "### Seaborn Library \n",
    "This library is a favorite among developers because it's easy to use and configure. \n",
    "\n",
    "#### YOUR ASSIGNMENT \n",
    "Change the display of data in the following ways:\n",
    "* Change the selection and amount of data being plotted\n",
    "* Change the color / appearance of the plot on consulting Seaborn's documentation on color palettes: https://seaborn.pydata.org/tutorial/color_palettes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60aa93f-3b4b-4db6-9f17-59af8e889a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to plot every last word here. But we have a lot of data, so we can experiment\n",
    "# To access data in our Counter list and keep it organized from highest to lowest value, we use `most_common()`.\n",
    "# Then we can slice it to store however many we want to plot. [:10] would plot the first 11 values since python starts counting from zero.\n",
    "\n",
    "mostCommon = dict(lemmaFreq.most_common()[:44])\n",
    "print(f\"mostCommon Lemmas {mostCommon}\")\n",
    "\n",
    "# Turns out after some tinkering that the seaborn library wants to collect its x and y values from lists. \n",
    "# So I'm just unpacking the values and keys, and checking to make sure they remain in their dictionary order here. \n",
    "counts = list(mostCommon.values())\n",
    "lems = list(mostCommon.keys())\n",
    "print(counts)\n",
    "print(lems)\n",
    "\n",
    "# This is to help matplotlib to display plots inline in the Jupyter Notebook\n",
    "%matplotlib inline\n",
    "# Set figure size configuration\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "# Create bar plot using seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=counts, y=lems, palette=\"magma\")\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.title('Most Common Lemmas')\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc77752-e826-4949-b334-0e934f4322ed",
   "metadata": {},
   "source": [
    "# Check out the SVG :-)\n",
    "The next cell is just here to show you what SVG code looks like \"under the hood\": SVG is a kind of XML, and we can output it programmatically to make shapes and lines and apply colors based on data. Click on the cell to see what the code looks like underneath: we'll be exploring this code in more detail soon! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99206dc3-8487-4153-be7b-f962a40148b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple.svg\n",
    "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100%\" height=\"100%\">\n",
    "    <desc><!--You could write a description of this SVG here.--></desc>\n",
    "    <g alignment-baseline=\"baseline\" transform=\"translate (25, 100)\">\n",
    "        <!--The \"g\" element just lets us *group* stuff together. -->\n",
    "        <circle cx=\"320\" cy=\"80\" r=\"50\" stroke=\"red\" fill=\"orange\" stroke-width=\"4\"/>  \n",
    "     <circle cx=\"250\" cy=\"150\" r=\"100\" stroke=\"red\" fill=\"purple\" stroke-width=\"4\"/>  \n",
    "        \n",
    "       \n",
    "        \n",
    "        <!--<line x1=\"25\" y1=\"-5\" x2=\"500\" y2=\"500\" stroke=\"red\" stroke-width=\"3\"/>-->\n",
    "        \n",
    "        <line x1=\"25\" y1=\"300\" x2=\"700\" y2=\"300\" stroke=\"purple\" stroke-width=\"20\"/>\n",
    "       <!--line above is the x axis of my graph -->\n",
    "        \n",
    "        <line x1=\"25\" y1=\"300\" x2=\"25\" y2=\"0\" stroke=\"green\" stroke-width=\"10\"/>\n",
    "        \n",
    "        <line x1=\"25\" y1=\"250\" x2=\"700\" y2=\"250\" stroke=\"purple\" stroke-width=\"2\"/>\n",
    "        \n",
    "        <text x=\"15\" y=\"230\" fill=\"purple\" style=\"font-family:serif;font-size:15px; writing-mode: tb; glyph-orientation-vertical: 5\">50</text>\n",
    "        \n",
    "        <line x1=\"25\" y1=\"100\" x2=\"700\" y2=\"100\" stroke=\"purple\" stroke-width=\"2\"/>\n",
    "        <text x=\"15\" y=\"90\" fill=\"purple\" style=\"font-family:sans-serif;font-size:15px; writing-mode: tb; glyph-orientation-horizontal: 5\">75</text>\n",
    "    </g>\n",
    "</svg>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853a94f-f358-4ea9-9643-1e1d46ffc231",
   "metadata": {},
   "source": [
    "<img src=\"simple.svg\" height=\"100%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd8e90-531a-49c9-9efd-f16621976c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
